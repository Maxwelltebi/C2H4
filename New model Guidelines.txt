Step 1: Set Up the Environment

Install Python and the necessary libraries:
If you haven't already, install Python. Then, install the necessary libraries:

pip install opencv-python tensorflow numpy matplotlib

Step 2: Prepare the Dataset

Collect a small dataset:

Take around 50–100 images of plastic items and 50–100 images of non-plastic items using your camera (e.g., plastic bottles, plastic bags, paper, metal cans, etc.).

Organize the images into two folders:

dataset/
    plastic/
        plastic_bottle1.jpg
        plastic_bottle2.jpg
        ...
    non_plastic/
        paper_bag1.jpg
        metal_can1.jpg
        ...


Resize and normalize the images:

Resize all images to 224x224 pixels to match the input size of the model.

Normalize the pixel values to the range [0, 1].

Step 3: Build and Train the Model

Import necessary libraries:

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam


Preprocess the images:

Load and resize images, then convert them into arrays.

image_size = 224  # resizing all images to 224x224 pixels
def load_images(image_folder):
    images = []
    labels = []
    for label, folder in enumerate(os.listdir(image_folder)):
        folder_path = os.path.join(image_folder, folder)
        for image_name in os.listdir(folder_path):
            image = cv2.imread(os.path.join(folder_path, image_name))
            image = cv2.resize(image, (image_size, image_size))
            images.append(image)
            labels.append(label)
    return np.array(images), np.array(labels)

images, labels = load_images('dataset')  # path to your dataset
images = images / 255.0  # normalize image data to [0, 1]


Build the CNN model:
We will use a simple Convolutional Neural Network (CNN) for this task.

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(2, activation='softmax')  # 2 classes: plastic or non-plastic
])

model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])


Train the model:

model.fit(images, labels, epochs=10, batch_size=16, validation_split=0.2)


This will train the model for 10 epochs and use 20% of the dataset for validation.

Step 4: Save the Model

Once the model is trained, you’ll want to save it so you can use it later for real-time predictions.

model.save('plastic_recognition_model.h5')

Step 5: Test the Model with Camera Feed

Now that the model is trained, let’s use it to classify objects in the camera feed.

Load the trained model:

model = tf.keras.models.load_model('plastic_recognition_model.h5')


Open the camera feed and preprocess each frame:

Capture frames from the camera, resize them to the input size, and preprocess them.

cap = cv2.VideoCapture(0)  # 0 for default camera

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Resize the image to fit the model input size (224x224)
    image = cv2.resize(frame, (224, 224))
    image = np.expand_dims(image, axis=0)  # Add batch dimension
    image = image / 255.0  # Normalize the image

    # Predict the class (plastic vs non-plastic)
    predictions = model.predict(image)
    predicted_class = np.argmax(predictions, axis=1)[0]  # 0: plastic, 1: non-plastic

    # Display the result on the frame
    if predicted_class == 0:
        text = "Plastic"
        color = (0, 255, 0)  # Green
    else:
        text = "Non-Plastic"
        color = (0, 0, 255)  # Red

    cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
    cv2.imshow('Plastic Recognition', frame)

    # Exit on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

Step 6: Test and Validate the System

Test the system:

When you raise an object in front of the camera, it will classify it as "Plastic" or "Non-Plastic" based on the trained model.

Exit the loop:

Press the 'q' key to exit the camera feed.

Summary:

You now have a complete system that:

Trains a model on a small dataset of plastic vs non-plastic items.

Tests the model on live camera feed.

Classifies objects as Plastic or Non-Plastic and displays the result on the camera window.

You can refine this model further by:

Adding more images for training

Experimenting with more complex models (e.g., MobileNetV2)

Improving the camera's feedback (e.g., by adding bounding boxes around objects or explaining predictions).